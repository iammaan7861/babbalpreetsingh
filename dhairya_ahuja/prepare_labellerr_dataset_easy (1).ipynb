{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIejM7bzRZdc"
      },
      "source": [
        "# Prepare Labellerr COCO dataset for YOLOv8-seg (easy notebook)\n",
        "\n",
        "This notebook helps you convert a single COCO JSON file (`export_coco.json`) and a folder with images into a `dataset/` layout ready for YOLOv8 segmentation training.\n",
        "\n",
        "**How to use (easy):**\n",
        "1. Upload your `export_coco.json` and your images folder to Google Drive.\n",
        "2. Edit the two path variables in the first code cell.\n",
        "3. Run cells sequentially (select `Runtime -> Change runtime type -> GPU` if you plan to train after).\n",
        "\n"
      ],
      "id": "hIejM7bzRZdc"
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick fix: set paths and check files. Edit the two paths below.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)   # mounts your Drive\n",
        "\n",
        "COCO_JSON_PATH = \"/content/drive/MyDrive/export_coco.json\"   # <- change if your json is elsewhere\n",
        "IMAGES_SRC_DIR  = \"/content/drive/MyDrive/cars_persons_images\"  # <- change to folder with your images\n",
        "\n",
        "OUTPUT_ROOT = \"/content/dataset_coco_labellerr_easy\"\n",
        "\n",
        "print(\"COCO JSON exists?\", os.path.exists(COCO_JSON_PATH))\n",
        "print(\"Images dir exists?\", os.path.exists(IMAGES_SRC_DIR))\n",
        "# list first 10 image files to verify\n",
        "import os\n",
        "imgs = [f for f in os.listdir(IMAGES_SRC_DIR) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
        "print(\"Number of images found:\", len(imgs))\n",
        "print(\"First 10 image names:\", imgs[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "7jBlfSg_S5Ny",
        "outputId": "9cab9951-466c-4419-bfeb-f93de833e0e4"
      },
      "id": "7jBlfSg_S5Ny",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1068665546.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Quick fix: set paths and check files. Edit the two paths below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# mounts your Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mCOCO_JSON_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/export_coco.json\"\u001b[0m   \u001b[0;31m# <- change if your json is elsewhere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jDPzE4mRZdg"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Mount Drive and set paths - EDIT these two paths only\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# === EDIT THESE PATHS ===\n",
        "COCO_JSON_PATH = \"C:\\Users\\User\\Downloads\\export-#VIrgMxUgk9LN2pH0qNwN (1).json\"   # path to your COCO JSON from Labellerr\n",
        "IMAGES_SRC_DIR  = \"E:\\labler\"  # folder containing all images (.jpg/.png)\n",
        "# ========================\n",
        "\n",
        "OUTPUT_ROOT = \"/content/dataset_coco_labellerr_easy\"\n",
        "print(\"COCO_JSON_PATH:\", COCO_JSON_PATH)\n",
        "print(\"IMAGES_SRC_DIR:\", IMAGES_SRC_DIR)\n",
        "print(\"OUTPUT_ROOT:\", OUTPUT_ROOT)\n"
      ],
      "id": "1jDPzE4mRZdg"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDbkW2hQRZdj"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Install small dependencies\n",
        "!pip install -q tqdm pycocotools ultralytics\n",
        "print('Installed tqdm, pycocotools, ultralytics')"
      ],
      "id": "WDbkW2hQRZdj"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B12w2XnRZdk"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Create train/val/test splits and COCO jsons (easy)\n",
        "import json, os, shutil, random\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO   = 0.15\n",
        "TEST_RATIO  = 0.15\n",
        "\n",
        "# Load COCO JSON\n",
        "with open(COCO_JSON_PATH, 'r') as f:\n",
        "    coco = json.load(f)\n",
        "\n",
        "images_info = coco.get('images', [])\n",
        "anns = coco.get('annotations', [])\n",
        "categories = coco.get('categories', [])\n",
        "\n",
        "if len(images_info) == 0:\n",
        "    raise SystemExit(\"No images in JSON. Make sure your COCO JSON contains 'images' entries.\")\n",
        "\n",
        "img_by_file = {im['file_name']: im for im in images_info}\n",
        "src_files = [f for f in os.listdir(IMAGES_SRC_DIR) if f.lower().endswith(('.jpg','.jpeg','.png','.tiff'))]\n",
        "\n",
        "common_files = [f for f in src_files if f in img_by_file]\n",
        "if len(common_files) == 0:\n",
        "    raise SystemExit(\"No common filenames between JSON and images folder. Check names (case-sensitive).\")\n",
        "\n",
        "random.shuffle(common_files)\n",
        "n = len(common_files)\n",
        "n_train = int(n * TRAIN_RATIO)\n",
        "n_val   = int(n * VAL_RATIO)\n",
        "n_test  = n - n_train - n_val\n",
        "\n",
        "train_files = common_files[:n_train]\n",
        "val_files   = common_files[n_train:n_train+n_val]\n",
        "test_files  = common_files[n_train+n_val:]\n",
        "\n",
        "print('Counts ->', len(train_files), 'train,', len(val_files), 'val,', len(test_files), 'test')\n",
        "\n",
        "# create structure and copy files\n",
        "for split, files in [('train', train_files), ('val', val_files), ('test', test_files)]:\n",
        "    dst_dir = Path(OUTPUT_ROOT) / 'images' / split\n",
        "    dst_dir.mkdir(parents=True, exist_ok=True)\n",
        "    for fname in tqdm(files, desc=f'Copying {split}'):\n",
        "        shutil.copy2(Path(IMAGES_SRC_DIR)/fname, dst_dir / fname)\n",
        "\n",
        "def build_coco_for(split_files):\n",
        "    imgs = [img_by_file[fname] for fname in split_files]\n",
        "    img_ids = {img['id'] for img in imgs}\n",
        "    anns_f = [a for a in anns if a['image_id'] in img_ids]\n",
        "    return {\"images\": imgs, \"annotations\": anns_f, \"categories\": categories}\n",
        "\n",
        "ann_dir = Path(OUTPUT_ROOT) / 'annotations'\n",
        "ann_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with open(ann_dir / 'train.json', 'w') as f:\n",
        "    json.dump(build_coco_for(train_files), f)\n",
        "with open(ann_dir / 'val.json', 'w') as f:\n",
        "    json.dump(build_coco_for(val_files), f)\n",
        "with open(ann_dir / 'test.json', 'w') as f:\n",
        "    json.dump(build_coco_for(test_files), f)\n",
        "\n",
        "print('Wrote split JSONs to', ann_dir)\n"
      ],
      "id": "3B12w2XnRZdk"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noO1PrdZRZdl"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Write data.yaml compatible with YOLOv8 (COCO-style)\n",
        "from pathlib import Path\n",
        "out = Path(OUTPUT_ROOT)\n",
        "cats = {c['id']: c['name'] for c in categories}\n",
        "sorted_cats = [cats[k] for k in sorted(cats.keys())]\n",
        "data_yaml = {\n",
        "    \"train\": str(out / \"annotations\" / \"train.json\"),\n",
        "    \"val\":   str(out / \"annotations\" / \"val.json\"),\n",
        "    \"test\":  str(out / \"annotations\" / \"test.json\"),\n",
        "    \"nc\": len(sorted_cats),\n",
        "    \"names\": sorted_cats\n",
        "}\n",
        "import yaml\n",
        "with open(out / 'data.yaml', 'w') as f:\n",
        "    yaml.dump(data_yaml, f)\n",
        "print('Wrote data.yaml at', out / 'data.yaml')\n",
        "print(data_yaml)"
      ],
      "id": "noO1PrdZRZdl"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROS_ZL9ERZdl"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Quick verify\n",
        "!ls -R /content/dataset_coco_labellerr_easy | sed -n '1,200p'"
      ],
      "id": "ROS_ZL9ERZdl"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bfd52dP-RZdm"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Example: start a short training run (uncomment to run)\n",
        "# from ultralytics import YOLO\n",
        "# model = YOLO('yolov8n-seg.pt')\n",
        "# model.train(data='/content/dataset_coco_labellerr_easy/data.yaml', epochs=10, imgsz=640, batch=8, name='labellerr_easy_test')\n",
        "print('If you want to train, uncomment the training block and run this cell (make sure GPU runtime).')"
      ],
      "id": "Bfd52dP-RZdm"
    }
  ]
}